{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Grid testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:20:29.732280: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-23 20:20:29.816541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742757629.951184 1123066 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742757629.974211 1123066 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742757630.047407 1123066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742757630.047443 1123066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742757630.047445 1123066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742757630.047447 1123066 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-23 20:20:30.071018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargé 3161088 lignes pour la période de 2024-12-05 00:00:00 à 2025-03-12 23:00:00\n"
     ]
    }
   ],
   "source": [
    "from velibds import VelibData, VelibDataViz as viz\n",
    "import plotly.express as px\n",
    "from velibds.modelisation import MLP, show_prediction_report, station_graph, BaseRegressor\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE, mean_absolute_error as MAE\n",
    "from keras.optimizers import Optimizer, Adam, AdamW, Nadam, SGD\n",
    "from pathlib import Path\n",
    "import datetime, os, pandas as pd, numpy as np\n",
    "now = datetime.datetime.now\n",
    "\n",
    "\n",
    "# Laisse BLIND = True, cela va pas generer les graphiques pendant le run donc pas de VSCODE planté...\n",
    "BLIND = True\n",
    "# BLIND = False\n",
    "\n",
    "# Est-ce qu'on va charger et remplir un df_results déjà existant?\n",
    "LOADED = True\n",
    "\n",
    "# Faut-il ajouter des lags et si oui, combien?\n",
    "# LAGS = 3\n",
    "LAGS = 0\n",
    "\n",
    "# Date marge de train et test\n",
    "SPLIT_DATE = datetime.date(2025, 2, 15)\n",
    "# Date minimale pour train\n",
    "LOW_LIMIT = datetime.date(2024, 12, 1)\n",
    "\n",
    "# On va charger le dataset du csv?\n",
    "CACHED = True\n",
    "# CACHED = False\n",
    "\n",
    "# Path dataset\n",
    "dataset_file = r'local_data/dataset.csv'\n",
    "\n",
    "# ID de la station Chatelet\n",
    "chatelet = '82328045'\n",
    "\n",
    "# Features à customizer:\n",
    "FEATURES = MLP.FEATURES\n",
    "\n",
    "def prepare_dataset():\n",
    "    os.environ['LOKY_MAX_CPU_COUNT'] = '7'\n",
    "    df = VelibData(update_cache=True).extract().transform().data\n",
    "    # df = VelibData(cache=True).extract().transform().data\n",
    "    df.to_csv(dataset_file, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "if CACHED and Path(dataset_file).is_file():\n",
    "    df = pd.read_csv(dataset_file, parse_dates=['datehour'])\n",
    "    print(f'Chargé {len(df)} lignes pour la période de {df.datehour.min()} à {df.datehour.max()}')\n",
    "else:\n",
    "    df = prepare_dataset()\n",
    "\n",
    "### Ajoute des lags:\n",
    "if LAGS:\n",
    "    for lag in range(1, LAGS + 1):\n",
    "        col = f'lag_{lag}'\n",
    "        df[col] = df.groupby('station')['delta'].shift(lag)\n",
    "        FEATURES.append(col)\n",
    "    df = df.dropna()\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Train test split par date\n",
    "df_train = df_orig[(df.datehour.dt.date < SPLIT_DATE) & (df.datehour.dt.date >= LOW_LIMIT)].copy()\n",
    "df_test = df_orig[(df.datehour.dt.date >= SPLIT_DATE)].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_tasks = []\n",
    "mlp_tasks = []\n",
    "history = {}\n",
    "df_results = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "settings_file = r'grid_settings.json'\n",
    "df_results_file = r'df_results.h5'\n",
    "history_file = r'history.json'\n",
    "\n",
    "known_optimizers = [Adam, AdamW, Nadam, SGD,]\n",
    "known_optimizers_str = [c.__name__ for c in known_optimizers]\n",
    "\n",
    "def load_all():\n",
    "    global df_results, history, classic_tasks, mlp_tasks\n",
    "    print(now(), 'Loading all data...')\n",
    "    if Path(settings_file).is_file():\n",
    "        with open(settings_file, 'r') as f:\n",
    "            settings = json.load(f)\n",
    "        if settings.get('SPLIT_DATE') != SPLIT_DATE.strftime('%Y-%m-%y'):\n",
    "            warnings.warn('SPLIT_DATE is different in settings! Skip restoring.')\n",
    "            return\n",
    "        classic_tasks = settings.get('classic_tasks', []) or classic_tasks\n",
    "        for ct in classic_tasks:\n",
    "            ct['__MODEL'] = deserialize_regressor(ct['__NAME'], ct['__MODEL'])\n",
    "        mlp_tasks = settings.get('mlp_tasks', []) or mlp_tasks\n",
    "        for mt in mlp_tasks:\n",
    "            mt['optimizer'] = deserialize_optimizer(mt['optimizer'], mt['__optimizer_settings'])\n",
    "    if Path(df_results_file).is_file():\n",
    "        # df_results = pd.read_csv(df_results_file, index_col=0)        \n",
    "        df_results = pd.read_hdf(df_results_file, key='df')        \n",
    "    if Path(history_file).is_file():\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "    print(now(), 'All data loaded...')\n",
    "    \n",
    "def serialize_regressor(name, model):\n",
    "    if isinstance(model, (tuple, list)):\n",
    "        model, model_name = model\n",
    "    else:\n",
    "        model_name = model.__class__.__name__\n",
    "    joblib.dump(model, 'local_data/' + name + '@' + model_name + '.joblib')\n",
    "    return model_name\n",
    "\n",
    "def deserialize_regressor(name, model_name : str):\n",
    "    model = joblib.load('local_data/' + name + '@' + model_name + '.joblib')\n",
    "    return model\n",
    "\n",
    "def serialize_optimizer(opt):\n",
    "    return opt.__class__.__name__\n",
    "\n",
    "def deserialize_optimizer(opt_name : str, opt_settings : dict):\n",
    "    opt_class = known_optimizers[known_optimizers_str.index(opt_name)]\n",
    "    return opt_class(**opt_settings)\n",
    "\n",
    "def save_all():\n",
    "    print(now(), 'Saving all data...')\n",
    "    fixed_classic_tasks = classic_tasks.copy()\n",
    "    for i, ct in enumerate(fixed_classic_tasks):\n",
    "        ct = ct.copy()\n",
    "        fixed_classic_tasks[i] = ct\n",
    "        ct['__MODEL'] = serialize_regressor(ct['__NAME'], ct['__MODEL'])\n",
    "    fixed_mlp_tasks = mlp_tasks.copy()\n",
    "    for i, mt in enumerate(fixed_mlp_tasks):\n",
    "        mt = mt.copy()\n",
    "        fixed_mlp_tasks[i] = mt\n",
    "        mt['optimizer'] = serialize_optimizer(mt['optimizer'])\n",
    "    settings = {\n",
    "        'SPLIT_DATE' : SPLIT_DATE.strftime('%Y-%m-%y'),\n",
    "        'classic_tasks' : fixed_classic_tasks,\n",
    "        'mlp_tasks' : fixed_mlp_tasks\n",
    "    }\n",
    "    with open(settings_file, 'w') as f:\n",
    "        json.dump(settings, f)\n",
    "    with open(history_file, 'w') as f:\n",
    "        json.dump(history, f)\n",
    "    print(now(), 'Saving results dataset...')\n",
    "    # df_results.to_csv(df_results_file)\n",
    "    df_results.to_hdf(df_results_file, mode='w', key='df')\n",
    "    print(now(), 'All data saved...')\n",
    "\n",
    "\n",
    "def common_output(wrapper : MLP, df_results, y_pred, y_col = 'delta'):\n",
    "    name = wrapper.NAME\n",
    "    pred_col = 'pred__' + name\n",
    "    df_results[pred_col] = y_pred.round()\n",
    "    df_results[pred_col] = df_results[pred_col].astype('int8')\n",
    "    history[name] = wrapper.history\n",
    "\n",
    "def optimize_df_results(df_results : pd.DataFrame):\n",
    "    cols = df_results.columns[df_results.columns.str.startswith('pred__')].to_list()\n",
    "    for c in cols:\n",
    "        df_results[c] = df_results[c].round().astype('int8')\n",
    "    df_results['bikes'] = df_results['bikes'].astype('int8')\n",
    "    df_results['capacity'] = df_results['capacity'].astype('int8')\n",
    "    df_results['delta'] = df_results['delta'].astype('int8')\n",
    "    return df_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE, root_mean_squared_error as RMSE\n",
    "\n",
    "\n",
    "\n",
    "xgb1 = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.6,\n",
    "    max_depth=10,\n",
    "    subsample=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=10\n",
    ")\n",
    "xgb2 = XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.6, reg_lambda=0.1)\n",
    "xgb3 = XGBRegressor()\n",
    "models = [(LinearRegression(), 'LinReg'), (BayesianRidge(), 'Baye'), (xgb1, 'XGBRegressor_max'), (xgb2, 'XGBRegressor_med'), (xgb3, 'XGBRegressor_default')]\n",
    "\n",
    "top_bottom_weights = [\n",
    "    (7, 7),\n",
    "    (10, 10),\n",
    "    # (10, 15),\n",
    "    # (20, 30),\n",
    "    (50, 70) \n",
    "    ]\n",
    "sampling = [None, ('u', 3), ('u', 1), ('o', 3), ('o', 6)]\n",
    "lrs = [0.001, 0.003, 0.006]\n",
    "optimizers = [\n",
    "    {'class' : Adam,\n",
    "     'tag' : 'adam',\n",
    "     'args' : {}\n",
    "    },\n",
    "    {'class' : AdamW,\n",
    "     'tag' : 'adamw',\n",
    "     'args' : {}\n",
    "    },\n",
    "    {'class' : SGD,\n",
    "     'tag' : 'sgd',\n",
    "     'args' : {'nesterov' : True}\n",
    "    },\n",
    "]\n",
    "activators = [\n",
    "    'relu',\n",
    "    'tanh'\n",
    "]\n",
    "epochs = [\n",
    "    # 10,\n",
    "    # 50,\n",
    "    # 150,\n",
    "    300\n",
    "    ]\n",
    "\n",
    "def generate_classical_settings():\n",
    "    classical_settings = []\n",
    "    for m in models:\n",
    "        for s in sampling:\n",
    "            for w in top_bottom_weights:\n",
    "                current_settings = {}\n",
    "                if not isinstance(m, (tuple, list)):\n",
    "                    m = (m, m.__class__.__name__)\n",
    "                tags = ['reg', m[1]]\n",
    "                current_settings['__MODEL'] = m[0]\n",
    "                if s is not None:\n",
    "                    if s[0] == 'o':\n",
    "                        current_settings['OVERSAMPLE'] = s[1]\n",
    "                        tags.append(f'o{s[1]}')\n",
    "                    elif s[0] == 'u':\n",
    "                        current_settings['UNDERSAMPLE'] = s[1]\n",
    "                        tags.append(f'u{s[1]}')\n",
    "                current_settings['WEIGHTS'] = True\n",
    "                current_settings['TOP_WEIGHT'] = w[0]\n",
    "                current_settings['BOTTOM_WEIGHT'] = w[1]\n",
    "                tags.append(f'w{w[0]}w{w[1]}')\n",
    "                current_settings['__NAME'] = '_'.join(tags)\n",
    "                classical_settings.append(current_settings)\n",
    "    return classical_settings\n",
    "\n",
    "def generate_mlp_settings():\n",
    "    mlp_settings = []\n",
    "    for e in epochs:\n",
    "        for opt in optimizers:\n",
    "            for a in activators:\n",
    "                for rate in lrs:\n",
    "                    for s in sampling:\n",
    "                        for w in top_bottom_weights:\n",
    "                            current_settings = {}\n",
    "                            tags = ['mlp']\n",
    "                            current_settings['__FIT'] = {'epochs' : e}\n",
    "                            tags.append(f'e{e}')\n",
    "                            current_settings['__optimizer_settings'] = (opt.get('args', {}) | {'learning_rate' : rate})\n",
    "                            current_settings['optimizer'] = opt['class'](learning_rate=rate, **opt.get('args', {}))\n",
    "                            tags.append(opt.get('tag', ''))\n",
    "                            tags.append(f'lr{int(rate*1000)}')\n",
    "                            if s is not None:\n",
    "                                if s[0] == 'o':\n",
    "                                    current_settings['OVERSAMPLE'] = s[1]\n",
    "                                    tags.append(f'o{s[1]}')\n",
    "                                elif s[0] == 'u':\n",
    "                                    current_settings['UNDERSAMPLE'] = s[1]\n",
    "                                    tags.append(f'u{s[1]}')\n",
    "                            current_settings['WEIGHTS'] = True\n",
    "                            current_settings['TOP_WEIGHT'] = w[0]\n",
    "                            current_settings['BOTTOM_WEIGHT'] = w[1]\n",
    "                            tags.append(f'w{w[0]}w{w[1]}')\n",
    "                            current_settings['ACTIVATION'] = a\n",
    "                            tags.append(a)\n",
    "                            current_settings['__NAME'] = '_'.join(tags)\n",
    "                            mlp_settings.append(current_settings)\n",
    "    return  mlp_settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:21:02.107870 Loading all data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742757664.763475 1123066 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:21:11.259278 All data loaded...\n"
     ]
    }
   ],
   "source": [
    "if LOADED:\n",
    "    load_all()\n",
    "settings_basic = generate_classical_settings()\n",
    "settings_mlp = generate_mlp_settings()\n",
    "known_names = [v.get('__NAME') for v in classic_tasks + mlp_tasks]\n",
    "new_classic_tasks_count = len(classic_tasks)\n",
    "classic_tasks = classic_tasks + [v for v in settings_basic if v.get('__NAME') not in known_names]\n",
    "new_classic_tasks_count = len(classic_tasks) - new_classic_tasks_count \n",
    "new_mlp_tasks_count = len(mlp_tasks)\n",
    "mlp_tasks = mlp_tasks + [v for v in settings_mlp if v.get('__NAME') not in known_names]\n",
    "new_mlp_tasks_count = len(mlp_tasks) - new_mlp_tasks_count\n",
    "done_tasks = df_results.columns[df_results.columns.str.startswith('pred__')].str.replace('pred__', '').to_list()\n",
    "if new_mlp_tasks_count or new_classic_tasks_count:\n",
    "    save_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primo: les classiques avec un dataset reconstruit\n",
    "data_changed = False\n",
    "prefix = 'full_'\n",
    "try:\n",
    "    for t in classic_tasks:\n",
    "        model = t['__MODEL']\n",
    "        name = prefix + t['__NAME']\n",
    "        if name in done_tasks:\n",
    "            print(now(), f'Task is done: {name}')\n",
    "            continue\n",
    "        print(now(), f'Fitting {name}')\n",
    "        wrapper = BaseRegressor(model, name).update_settings(t).fit(df_train, df_train.delta)\n",
    "        print(now(), f'Prediction {name}')\n",
    "        y_pred = wrapper.predict(df_test)\n",
    "        common_output(wrapper, df_results, y_pred)\n",
    "        done_tasks.append(name)\n",
    "        data_changed = True\n",
    "finally:\n",
    "    if data_changed:\n",
    "        save_all()\n",
    "    \n",
    "# Duo: maintenant avec un dataset sans reconstructions...\n",
    "df_train = df_train[~df_train.reconstructed].copy()\n",
    "data_changed = False\n",
    "prefix = ''\n",
    "try:\n",
    "    for t in classic_tasks:\n",
    "        model = t['__MODEL']\n",
    "        name = prefix + t['__NAME']\n",
    "        if name in done_tasks:\n",
    "            print(now(), f'Task is done: {name}')\n",
    "            continue\n",
    "        print(now(), f'Fitting {name}')\n",
    "        wrapper = BaseRegressor(model, name).update_settings(t).fit(df_train, df_train.delta)\n",
    "        print(now(), f'Prediction {name}')\n",
    "        y_pred = wrapper.predict(df_test)\n",
    "        common_output(wrapper, df_results, y_pred)\n",
    "        done_tasks.append(name)\n",
    "        data_changed = True\n",
    "finally:\n",
    "    if data_changed:\n",
    "        save_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:21:19.095308 Task is done: mlp_e300_adam_lr1_w7w7_relu\n",
      "2025-03-23 20:21:19.095573 Task is done: mlp_e300_adam_lr1_w10w10_relu\n",
      "2025-03-23 20:21:19.095610 Task is done: mlp_e300_adam_lr1_w50w70_relu\n",
      "2025-03-23 20:21:19.095633 Task is done: mlp_e300_adam_lr1_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.095653 Task is done: mlp_e300_adam_lr1_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.095694 Task is done: mlp_e300_adam_lr1_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.095726 Task is done: mlp_e300_adam_lr1_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.095751 Task is done: mlp_e300_adam_lr1_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.095774 Task is done: mlp_e300_adam_lr1_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.095800 Task is done: mlp_e300_adam_lr1_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.095824 Task is done: mlp_e300_adam_lr1_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.095845 Task is done: mlp_e300_adam_lr1_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.095866 Task is done: mlp_e300_adam_lr1_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.095887 Task is done: mlp_e300_adam_lr1_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.095908 Task is done: mlp_e300_adam_lr1_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.095970 Task is done: mlp_e300_adam_lr3_w7w7_relu\n",
      "2025-03-23 20:21:19.095992 Task is done: mlp_e300_adam_lr3_w10w10_relu\n",
      "2025-03-23 20:21:19.096016 Task is done: mlp_e300_adam_lr3_w50w70_relu\n",
      "2025-03-23 20:21:19.096032 Task is done: mlp_e300_adam_lr3_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.096047 Task is done: mlp_e300_adam_lr3_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.096062 Task is done: mlp_e300_adam_lr3_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.096077 Task is done: mlp_e300_adam_lr3_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.096092 Task is done: mlp_e300_adam_lr3_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.096107 Task is done: mlp_e300_adam_lr3_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.096125 Task is done: mlp_e300_adam_lr3_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.096146 Task is done: mlp_e300_adam_lr3_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.096166 Task is done: mlp_e300_adam_lr3_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.096186 Task is done: mlp_e300_adam_lr3_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.096205 Task is done: mlp_e300_adam_lr3_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.096226 Task is done: mlp_e300_adam_lr3_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.096247 Task is done: mlp_e300_adam_lr6_w7w7_relu\n",
      "2025-03-23 20:21:19.096265 Task is done: mlp_e300_adam_lr6_w10w10_relu\n",
      "2025-03-23 20:21:19.096280 Task is done: mlp_e300_adam_lr6_w50w70_relu\n",
      "2025-03-23 20:21:19.096296 Task is done: mlp_e300_adam_lr6_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.096311 Task is done: mlp_e300_adam_lr6_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.096326 Task is done: mlp_e300_adam_lr6_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.096341 Task is done: mlp_e300_adam_lr6_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.096356 Task is done: mlp_e300_adam_lr6_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.096371 Task is done: mlp_e300_adam_lr6_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.096386 Task is done: mlp_e300_adam_lr6_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.096400 Task is done: mlp_e300_adam_lr6_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.096415 Task is done: mlp_e300_adam_lr6_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.096430 Task is done: mlp_e300_adam_lr6_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.096445 Task is done: mlp_e300_adam_lr6_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.096460 Task is done: mlp_e300_adam_lr6_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.096475 Task is done: mlp_e300_adam_lr1_w7w7_tanh\n",
      "2025-03-23 20:21:19.096490 Task is done: mlp_e300_adam_lr1_w10w10_tanh\n",
      "2025-03-23 20:21:19.096504 Task is done: mlp_e300_adam_lr1_w50w70_tanh\n",
      "2025-03-23 20:21:19.096519 Task is done: mlp_e300_adam_lr1_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.096533 Task is done: mlp_e300_adam_lr1_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.096548 Task is done: mlp_e300_adam_lr1_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.096563 Task is done: mlp_e300_adam_lr1_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.096578 Task is done: mlp_e300_adam_lr1_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.096595 Task is done: mlp_e300_adam_lr1_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.096616 Task is done: mlp_e300_adam_lr1_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.096638 Task is done: mlp_e300_adam_lr1_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.096659 Task is done: mlp_e300_adam_lr1_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.096680 Task is done: mlp_e300_adam_lr1_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.096702 Task is done: mlp_e300_adam_lr1_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.096723 Task is done: mlp_e300_adam_lr1_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.096746 Task is done: mlp_e300_adam_lr3_w7w7_tanh\n",
      "2025-03-23 20:21:19.096768 Task is done: mlp_e300_adam_lr3_w10w10_tanh\n",
      "2025-03-23 20:21:19.096789 Task is done: mlp_e300_adam_lr3_w50w70_tanh\n",
      "2025-03-23 20:21:19.096809 Task is done: mlp_e300_adam_lr3_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.096831 Task is done: mlp_e300_adam_lr3_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.096853 Task is done: mlp_e300_adam_lr3_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.096876 Task is done: mlp_e300_adam_lr3_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.096892 Task is done: mlp_e300_adam_lr3_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.096908 Task is done: mlp_e300_adam_lr3_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.096924 Task is done: mlp_e300_adam_lr3_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.096940 Task is done: mlp_e300_adam_lr3_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.096956 Task is done: mlp_e300_adam_lr3_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.096975 Task is done: mlp_e300_adam_lr3_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.097032 Task is done: mlp_e300_adam_lr3_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.097078 Task is done: mlp_e300_adam_lr3_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.097099 Task is done: mlp_e300_adam_lr6_w7w7_tanh\n",
      "2025-03-23 20:21:19.097120 Task is done: mlp_e300_adam_lr6_w10w10_tanh\n",
      "2025-03-23 20:21:19.097143 Task is done: mlp_e300_adam_lr6_w50w70_tanh\n",
      "2025-03-23 20:21:19.097166 Task is done: mlp_e300_adam_lr6_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.097181 Task is done: mlp_e300_adam_lr6_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.097197 Task is done: mlp_e300_adam_lr6_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.097212 Task is done: mlp_e300_adam_lr6_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.097228 Task is done: mlp_e300_adam_lr6_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.097243 Task is done: mlp_e300_adam_lr6_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.097272 Task is done: mlp_e300_adam_lr6_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.097293 Task is done: mlp_e300_adam_lr6_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.097314 Task is done: mlp_e300_adam_lr6_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.097334 Task is done: mlp_e300_adam_lr6_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.097356 Task is done: mlp_e300_adam_lr6_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.097378 Task is done: mlp_e300_adam_lr6_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.097399 Task is done: mlp_e300_adamw_lr1_w7w7_relu\n",
      "2025-03-23 20:21:19.097420 Task is done: mlp_e300_adamw_lr1_w10w10_relu\n",
      "2025-03-23 20:21:19.097441 Task is done: mlp_e300_adamw_lr1_w50w70_relu\n",
      "2025-03-23 20:21:19.097461 Task is done: mlp_e300_adamw_lr1_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.097483 Task is done: mlp_e300_adamw_lr1_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.097505 Task is done: mlp_e300_adamw_lr1_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.097562 Task is done: mlp_e300_adamw_lr1_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.097589 Task is done: mlp_e300_adamw_lr1_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.097610 Task is done: mlp_e300_adamw_lr1_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.097631 Task is done: mlp_e300_adamw_lr1_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.097654 Task is done: mlp_e300_adamw_lr1_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.097674 Task is done: mlp_e300_adamw_lr1_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.097721 Task is done: mlp_e300_adamw_lr1_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.097750 Task is done: mlp_e300_adamw_lr1_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.097772 Task is done: mlp_e300_adamw_lr1_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.097796 Task is done: mlp_e300_adamw_lr3_w7w7_relu\n",
      "2025-03-23 20:21:19.097818 Task is done: mlp_e300_adamw_lr3_w10w10_relu\n",
      "2025-03-23 20:21:19.097841 Task is done: mlp_e300_adamw_lr3_w50w70_relu\n",
      "2025-03-23 20:21:19.097866 Task is done: mlp_e300_adamw_lr3_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.097887 Task is done: mlp_e300_adamw_lr3_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.097909 Task is done: mlp_e300_adamw_lr3_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.097932 Task is done: mlp_e300_adamw_lr3_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.097955 Task is done: mlp_e300_adamw_lr3_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.097971 Task is done: mlp_e300_adamw_lr3_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.097987 Task is done: mlp_e300_adamw_lr3_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.098002 Task is done: mlp_e300_adamw_lr3_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.098018 Task is done: mlp_e300_adamw_lr3_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.098034 Task is done: mlp_e300_adamw_lr3_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.098050 Task is done: mlp_e300_adamw_lr3_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.098066 Task is done: mlp_e300_adamw_lr3_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.098082 Task is done: mlp_e300_adamw_lr6_w7w7_relu\n",
      "2025-03-23 20:21:19.098100 Task is done: mlp_e300_adamw_lr6_w10w10_relu\n",
      "2025-03-23 20:21:19.098116 Task is done: mlp_e300_adamw_lr6_w50w70_relu\n",
      "2025-03-23 20:21:19.098132 Task is done: mlp_e300_adamw_lr6_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.098147 Task is done: mlp_e300_adamw_lr6_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.098163 Task is done: mlp_e300_adamw_lr6_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.098182 Task is done: mlp_e300_adamw_lr6_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.098204 Task is done: mlp_e300_adamw_lr6_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.098221 Task is done: mlp_e300_adamw_lr6_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.098237 Task is done: mlp_e300_adamw_lr6_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.098260 Task is done: mlp_e300_adamw_lr6_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.098282 Task is done: mlp_e300_adamw_lr6_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.098298 Task is done: mlp_e300_adamw_lr6_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.098314 Task is done: mlp_e300_adamw_lr6_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.098330 Task is done: mlp_e300_adamw_lr6_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.098346 Task is done: mlp_e300_adamw_lr1_w7w7_tanh\n",
      "2025-03-23 20:21:19.098361 Task is done: mlp_e300_adamw_lr1_w10w10_tanh\n",
      "2025-03-23 20:21:19.098377 Task is done: mlp_e300_adamw_lr1_w50w70_tanh\n",
      "2025-03-23 20:21:19.098393 Task is done: mlp_e300_adamw_lr1_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.098409 Task is done: mlp_e300_adamw_lr1_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.098425 Task is done: mlp_e300_adamw_lr1_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.098440 Task is done: mlp_e300_adamw_lr1_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.098456 Task is done: mlp_e300_adamw_lr1_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.098472 Task is done: mlp_e300_adamw_lr1_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.098487 Task is done: mlp_e300_adamw_lr1_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.098503 Task is done: mlp_e300_adamw_lr1_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.098519 Task is done: mlp_e300_adamw_lr1_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.098535 Task is done: mlp_e300_adamw_lr1_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.098551 Task is done: mlp_e300_adamw_lr1_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.098566 Task is done: mlp_e300_adamw_lr1_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.098582 Task is done: mlp_e300_adamw_lr3_w7w7_tanh\n",
      "2025-03-23 20:21:19.098598 Task is done: mlp_e300_adamw_lr3_w10w10_tanh\n",
      "2025-03-23 20:21:19.098688 Task is done: mlp_e300_adamw_lr3_w50w70_tanh\n",
      "2025-03-23 20:21:19.098720 Task is done: mlp_e300_adamw_lr3_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.098743 Task is done: mlp_e300_adamw_lr3_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.098765 Task is done: mlp_e300_adamw_lr3_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.098785 Task is done: mlp_e300_adamw_lr3_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.098808 Task is done: mlp_e300_adamw_lr3_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.098831 Task is done: mlp_e300_adamw_lr3_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.098855 Task is done: mlp_e300_adamw_lr3_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.098872 Task is done: mlp_e300_adamw_lr3_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.098888 Task is done: mlp_e300_adamw_lr3_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.098904 Task is done: mlp_e300_adamw_lr3_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.098920 Task is done: mlp_e300_adamw_lr3_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.098936 Task is done: mlp_e300_adamw_lr3_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.098952 Task is done: mlp_e300_adamw_lr6_w7w7_tanh\n",
      "2025-03-23 20:21:19.098968 Task is done: mlp_e300_adamw_lr6_w10w10_tanh\n",
      "2025-03-23 20:21:19.098984 Task is done: mlp_e300_adamw_lr6_w50w70_tanh\n",
      "2025-03-23 20:21:19.098999 Task is done: mlp_e300_adamw_lr6_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.099015 Task is done: mlp_e300_adamw_lr6_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.099031 Task is done: mlp_e300_adamw_lr6_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.099048 Task is done: mlp_e300_adamw_lr6_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.099064 Task is done: mlp_e300_adamw_lr6_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.099079 Task is done: mlp_e300_adamw_lr6_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.099096 Task is done: mlp_e300_adamw_lr6_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.099112 Task is done: mlp_e300_adamw_lr6_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.099128 Task is done: mlp_e300_adamw_lr6_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.099143 Task is done: mlp_e300_adamw_lr6_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.099159 Task is done: mlp_e300_adamw_lr6_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.099178 Task is done: mlp_e300_adamw_lr6_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.099229 Task is done: mlp_e300_sgd_lr1_w7w7_relu\n",
      "2025-03-23 20:21:19.099267 Task is done: mlp_e300_sgd_lr1_w10w10_relu\n",
      "2025-03-23 20:21:19.099291 Task is done: mlp_e300_sgd_lr1_w50w70_relu\n",
      "2025-03-23 20:21:19.099308 Task is done: mlp_e300_sgd_lr1_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.099325 Task is done: mlp_e300_sgd_lr1_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.099342 Task is done: mlp_e300_sgd_lr1_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.099358 Task is done: mlp_e300_sgd_lr1_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.099374 Task is done: mlp_e300_sgd_lr1_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.099390 Task is done: mlp_e300_sgd_lr1_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.099406 Task is done: mlp_e300_sgd_lr1_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.099422 Task is done: mlp_e300_sgd_lr1_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.099439 Task is done: mlp_e300_sgd_lr1_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.099455 Task is done: mlp_e300_sgd_lr1_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.099476 Task is done: mlp_e300_sgd_lr1_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.099499 Task is done: mlp_e300_sgd_lr1_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.099517 Task is done: mlp_e300_sgd_lr3_w7w7_relu\n",
      "2025-03-23 20:21:19.099533 Task is done: mlp_e300_sgd_lr3_w10w10_relu\n",
      "2025-03-23 20:21:19.099550 Task is done: mlp_e300_sgd_lr3_w50w70_relu\n",
      "2025-03-23 20:21:19.099567 Task is done: mlp_e300_sgd_lr3_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.099585 Task is done: mlp_e300_sgd_lr3_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.099601 Task is done: mlp_e300_sgd_lr3_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.099617 Task is done: mlp_e300_sgd_lr3_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.099633 Task is done: mlp_e300_sgd_lr3_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.099649 Task is done: mlp_e300_sgd_lr3_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.099666 Task is done: mlp_e300_sgd_lr3_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.099683 Task is done: mlp_e300_sgd_lr3_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.099714 Task is done: mlp_e300_sgd_lr3_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.099737 Task is done: mlp_e300_sgd_lr3_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.099754 Task is done: mlp_e300_sgd_lr3_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.099770 Task is done: mlp_e300_sgd_lr3_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.099786 Task is done: mlp_e300_sgd_lr6_w7w7_relu\n",
      "2025-03-23 20:21:19.099802 Task is done: mlp_e300_sgd_lr6_w10w10_relu\n",
      "2025-03-23 20:21:19.099819 Task is done: mlp_e300_sgd_lr6_w50w70_relu\n",
      "2025-03-23 20:21:19.099836 Task is done: mlp_e300_sgd_lr6_u3_w7w7_relu\n",
      "2025-03-23 20:21:19.099852 Task is done: mlp_e300_sgd_lr6_u3_w10w10_relu\n",
      "2025-03-23 20:21:19.099868 Task is done: mlp_e300_sgd_lr6_u3_w50w70_relu\n",
      "2025-03-23 20:21:19.099884 Task is done: mlp_e300_sgd_lr6_u1_w7w7_relu\n",
      "2025-03-23 20:21:19.099901 Task is done: mlp_e300_sgd_lr6_u1_w10w10_relu\n",
      "2025-03-23 20:21:19.099918 Task is done: mlp_e300_sgd_lr6_u1_w50w70_relu\n",
      "2025-03-23 20:21:19.099935 Task is done: mlp_e300_sgd_lr6_o3_w7w7_relu\n",
      "2025-03-23 20:21:19.099952 Task is done: mlp_e300_sgd_lr6_o3_w10w10_relu\n",
      "2025-03-23 20:21:19.099968 Task is done: mlp_e300_sgd_lr6_o3_w50w70_relu\n",
      "2025-03-23 20:21:19.099985 Task is done: mlp_e300_sgd_lr6_o6_w7w7_relu\n",
      "2025-03-23 20:21:19.100002 Task is done: mlp_e300_sgd_lr6_o6_w10w10_relu\n",
      "2025-03-23 20:21:19.100018 Task is done: mlp_e300_sgd_lr6_o6_w50w70_relu\n",
      "2025-03-23 20:21:19.100035 Task is done: mlp_e300_sgd_lr1_w7w7_tanh\n",
      "2025-03-23 20:21:19.100051 Task is done: mlp_e300_sgd_lr1_w10w10_tanh\n",
      "2025-03-23 20:21:19.100068 Task is done: mlp_e300_sgd_lr1_w50w70_tanh\n",
      "2025-03-23 20:21:19.100085 Task is done: mlp_e300_sgd_lr1_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100101 Task is done: mlp_e300_sgd_lr1_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100118 Task is done: mlp_e300_sgd_lr1_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100135 Task is done: mlp_e300_sgd_lr1_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.100151 Task is done: mlp_e300_sgd_lr1_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.100168 Task is done: mlp_e300_sgd_lr1_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.100185 Task is done: mlp_e300_sgd_lr1_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100201 Task is done: mlp_e300_sgd_lr1_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100218 Task is done: mlp_e300_sgd_lr1_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100235 Task is done: mlp_e300_sgd_lr1_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.100252 Task is done: mlp_e300_sgd_lr1_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.100269 Task is done: mlp_e300_sgd_lr1_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.100285 Task is done: mlp_e300_sgd_lr3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100302 Task is done: mlp_e300_sgd_lr3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100318 Task is done: mlp_e300_sgd_lr3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100335 Task is done: mlp_e300_sgd_lr3_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100352 Task is done: mlp_e300_sgd_lr3_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100368 Task is done: mlp_e300_sgd_lr3_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100385 Task is done: mlp_e300_sgd_lr3_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.100402 Task is done: mlp_e300_sgd_lr3_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.100421 Task is done: mlp_e300_sgd_lr3_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.100438 Task is done: mlp_e300_sgd_lr3_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100459 Task is done: mlp_e300_sgd_lr3_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100476 Task is done: mlp_e300_sgd_lr3_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100493 Task is done: mlp_e300_sgd_lr3_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.100510 Task is done: mlp_e300_sgd_lr3_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.100527 Task is done: mlp_e300_sgd_lr3_o6_w50w70_tanh\n",
      "2025-03-23 20:21:19.100544 Task is done: mlp_e300_sgd_lr6_w7w7_tanh\n",
      "2025-03-23 20:21:19.100561 Task is done: mlp_e300_sgd_lr6_w10w10_tanh\n",
      "2025-03-23 20:21:19.100578 Task is done: mlp_e300_sgd_lr6_w50w70_tanh\n",
      "2025-03-23 20:21:19.100595 Task is done: mlp_e300_sgd_lr6_u3_w7w7_tanh\n",
      "2025-03-23 20:21:19.100613 Task is done: mlp_e300_sgd_lr6_u3_w10w10_tanh\n",
      "2025-03-23 20:21:19.100630 Task is done: mlp_e300_sgd_lr6_u3_w50w70_tanh\n",
      "2025-03-23 20:21:19.100646 Task is done: mlp_e300_sgd_lr6_u1_w7w7_tanh\n",
      "2025-03-23 20:21:19.100663 Task is done: mlp_e300_sgd_lr6_u1_w10w10_tanh\n",
      "2025-03-23 20:21:19.101293 Task is done: mlp_e300_sgd_lr6_u1_w50w70_tanh\n",
      "2025-03-23 20:21:19.101312 Task is done: mlp_e300_sgd_lr6_o3_w7w7_tanh\n",
      "2025-03-23 20:21:19.101327 Task is done: mlp_e300_sgd_lr6_o3_w10w10_tanh\n",
      "2025-03-23 20:21:19.101342 Task is done: mlp_e300_sgd_lr6_o3_w50w70_tanh\n",
      "2025-03-23 20:21:19.101356 Task is done: mlp_e300_sgd_lr6_o6_w7w7_tanh\n",
      "2025-03-23 20:21:19.101370 Task is done: mlp_e300_sgd_lr6_o6_w10w10_tanh\n",
      "2025-03-23 20:21:19.101390 Task is done: mlp_e300_sgd_lr6_o6_w50w70_tanh\n"
     ]
    }
   ],
   "source": [
    "data_runs = 0\n",
    "for t in mlp_tasks:\n",
    "    name = t['__NAME']\n",
    "    if name in done_tasks:\n",
    "        print(now(), f'Task is done: {name}')\n",
    "        continue\n",
    "    try:\n",
    "        fit_settings = t['__FIT']\n",
    "        print(now(), f'Fitting {name}')\n",
    "        wrapper = MLP(name).update_settings(t).add_fit_params(fit_settings).add_fit_params({'batch_size' : 32768}).fit(df_train, df_train.delta).save()\n",
    "        print(now(), f'Prediction {name}')\n",
    "        y_pred = wrapper.predict(df_test)\n",
    "        common_output(wrapper, df_results, y_pred)\n",
    "        done_tasks.append(name)\n",
    "        data_runs += 1\n",
    "    except Exception as e:\n",
    "        data_runs = 100\n",
    "        raise e\n",
    "    finally:\n",
    "        if data_runs >= 3:\n",
    "            save_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Break!').with_traceback(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut down by metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m sampling = [(s[\u001b[32m0\u001b[39m], s[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m s != \u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m top_settings[\u001b[33m'\u001b[39m\u001b[33mresample\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     27\u001b[39m lrs = [\u001b[38;5;28mint\u001b[39m(lr) \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m top_settings[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m lr != \u001b[33m'\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     28\u001b[39m optimizers = [\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m : \u001b[43mAdam\u001b[49m,\n\u001b[32m     30\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m      \u001b[33m'\u001b[39m\u001b[33margs\u001b[39m\u001b[33m'\u001b[39m : {}\n\u001b[32m     32\u001b[39m     },\n\u001b[32m     33\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m : AdamW,\n\u001b[32m     34\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m'\u001b[39m\u001b[33madamw\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     35\u001b[39m      \u001b[33m'\u001b[39m\u001b[33margs\u001b[39m\u001b[33m'\u001b[39m : {}\n\u001b[32m     36\u001b[39m     },\n\u001b[32m     37\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m : SGD,\n\u001b[32m     38\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m'\u001b[39m\u001b[33msgd\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     39\u001b[39m      \u001b[33m'\u001b[39m\u001b[33margs\u001b[39m\u001b[33m'\u001b[39m : {\u001b[33m'\u001b[39m\u001b[33mnesterov\u001b[39m\u001b[33m'\u001b[39m : \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m     40\u001b[39m     },\n\u001b[32m     41\u001b[39m ]\n\u001b[32m     42\u001b[39m optimizers = [o \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m optimizers \u001b[38;5;28;01mif\u001b[39;00m o[\u001b[33m'\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m top_settings[\u001b[33m'\u001b[39m\u001b[33mopt\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     43\u001b[39m activators = [\n\u001b[32m     44\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     45\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtanh\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     46\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "top_settings = {'lr': {'1', '6'},\n",
    " 'weight': {'w10w10', 'w7w7'},\n",
    " 'opt': {'adam', 'adamw', 'sgd'},\n",
    " 'resample': {'None', 'o3'}}\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE, root_mean_squared_error as RMSE\n",
    "\n",
    "\n",
    "\n",
    "xgb1 = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.6,\n",
    "    max_depth=10,\n",
    "    subsample=0.5,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=10\n",
    ")\n",
    "xgb2 = XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.6, reg_lambda=0.1)\n",
    "xgb3 = XGBRegressor()\n",
    "models = [(LinearRegression(), 'LinReg'), (BayesianRidge(), 'Baye'), (xgb1, 'XGBRegressor_max'), (xgb2, 'XGBRegressor_med'), (xgb3, 'XGBRegressor_default')]\n",
    "\n",
    "top_bottom_weights = [(int(a) for a in w.split('w')[1:]) for w in top_settings['weight']]\n",
    "sampling = [(s[0], s[1]) if s != 'None' else None for s in top_settings['resample']]\n",
    "lrs = [int(lr) for lr in top_settings['lr'] if lr != 'None']\n",
    "optimizers = [\n",
    "    {'class' : Adam,\n",
    "     'tag' : 'adam',\n",
    "     'args' : {}\n",
    "    },\n",
    "    {'class' : AdamW,\n",
    "     'tag' : 'adamw',\n",
    "     'args' : {}\n",
    "    },\n",
    "    {'class' : SGD,\n",
    "     'tag' : 'sgd',\n",
    "     'args' : {'nesterov' : True}\n",
    "    },\n",
    "]\n",
    "optimizers = [o for o in optimizers if o['tag'] in top_settings['opt']]\n",
    "activators = [\n",
    "    'relu',\n",
    "    'tanh'\n",
    "]\n",
    "epochs = [\n",
    "    # 10,\n",
    "    # 50,\n",
    "    # 150,\n",
    "    300\n",
    "    ]\n",
    "\n",
    "def generate_classical_settings():\n",
    "    classical_settings = []\n",
    "    for m in models:\n",
    "        for s in sampling:\n",
    "            for w in top_bottom_weights:\n",
    "                current_settings = {}\n",
    "                if not isinstance(m, (tuple, list)):\n",
    "                    m = (m, m.__class__.__name__)\n",
    "                tags = ['reg', m[1]]\n",
    "                current_settings['__MODEL'] = m[0]\n",
    "                if s is not None:\n",
    "                    if s[0] == 'o':\n",
    "                        current_settings['OVERSAMPLE'] = s[1]\n",
    "                        tags.append(f'o{s[1]}')\n",
    "                    elif s[0] == 'u':\n",
    "                        current_settings['UNDERSAMPLE'] = s[1]\n",
    "                        tags.append(f'u{s[1]}')\n",
    "                current_settings['WEIGHTS'] = True\n",
    "                current_settings['TOP_WEIGHT'] = w[0]\n",
    "                current_settings['BOTTOM_WEIGHT'] = w[1]\n",
    "                tags.append(f'w{w[0]}w{w[1]}')\n",
    "                current_settings['__NAME'] = '_'.join(tags)\n",
    "                classical_settings.append(current_settings)\n",
    "    return classical_settings\n",
    "\n",
    "def generate_mlp_settings():\n",
    "    mlp_settings = []\n",
    "    for e in epochs:\n",
    "        for opt in optimizers:\n",
    "            for a in activators:\n",
    "                for rate in lrs:\n",
    "                    for s in sampling:\n",
    "                        for w in top_bottom_weights:\n",
    "                            current_settings = {}\n",
    "                            tags = ['mlp']\n",
    "                            current_settings['__FIT'] = {'epochs' : e}\n",
    "                            tags.append(f'e{e}')\n",
    "                            current_settings['__optimizer_settings'] = (opt.get('args', {}) | {'learning_rate' : rate})\n",
    "                            current_settings['optimizer'] = opt['class'](learning_rate=rate, **opt.get('args', {}))\n",
    "                            tags.append(opt.get('tag', ''))\n",
    "                            tags.append(f'lr{int(rate*1000)}')\n",
    "                            if s is not None:\n",
    "                                if s[0] == 'o':\n",
    "                                    current_settings['OVERSAMPLE'] = s[1]\n",
    "                                    tags.append(f'o{s[1]}')\n",
    "                                elif s[0] == 'u':\n",
    "                                    current_settings['UNDERSAMPLE'] = s[1]\n",
    "                                    tags.append(f'u{s[1]}')\n",
    "                            current_settings['WEIGHTS'] = True\n",
    "                            current_settings['TOP_WEIGHT'] = w[0]\n",
    "                            current_settings['BOTTOM_WEIGHT'] = w[1]\n",
    "                            tags.append(f'w{w[0]}w{w[1]}')\n",
    "                            current_settings['ACTIVATION'] = a\n",
    "                            tags.append(a)\n",
    "                            current_settings['__NAME'] = '_'.join(tags)\n",
    "                            mlp_settings.append(current_settings)\n",
    "    return  mlp_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duo: maintenant avec un dataset sans reconstructions...\n",
    "df_train = df_train[~df_train.reconstructed].copy()\n",
    "data_changed = False\n",
    "prefix = 'lag'\n",
    "try:\n",
    "    for t in classic_tasks:\n",
    "        model = t['__MODEL']\n",
    "        name = prefix + t['__NAME']\n",
    "        if name in done_tasks:\n",
    "            print(now(), f'Task is done: {name}')\n",
    "            continue\n",
    "        print(now(), f'Fitting {name}')\n",
    "        wrapper = BaseRegressor(model, name).update_features(FEATURES).update_settings(t).fit(df_train, df_train.delta)\n",
    "        print(now(), f'Prediction {name}')\n",
    "        y_pred = wrapper.predict(df_test)\n",
    "        common_output(wrapper, df_results, y_pred)\n",
    "        done_tasks.append(name)\n",
    "        data_changed = True\n",
    "finally:\n",
    "    if data_changed:\n",
    "        save_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
