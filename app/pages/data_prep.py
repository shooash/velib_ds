import streamlit as st
import pandas as pd
import plotly.express as px
from velibdslib import get_border, points_to_geo_json, draw_stations_choroplethmap_scatter

def show(): 
    st.title("Exploration des donnÃ©es VÃ©lib' Paris")

    st.markdown("""
    ## ğŸ” Contexte du projet
    Ce projet a pour objectif d'optimiser la disponibilitÃ© des vÃ©los du service VÃ©libâ€™ Ã  Paris, en cherchant Ã  prÃ©dire les flux de vÃ©los (nombre dâ€™emprunts et de retours) Ã  chaque station.
    """)

    st.markdown("""
    ## ğŸ§± Construction de la base de donnÃ©es
    Les donnÃ©es ont Ã©tÃ© extraites des API Open Data de VÃ©libâ€™ (station_status et station_information) et collectÃ©es toutes les heures via un script sur Google Cloud Run.

    Elles sont stockÃ©es dans deux tables principales :
    - **velib_status** : Ã©tat en temps rÃ©el des stations (vÃ©los disponibles, bornes, etc.)
    - **velib_stations** : informations statiques (nom, localisation, capacitÃ©)

    Ces deux sources ont Ã©tÃ© fusionnÃ©es dans une vue unifiÃ©e : `velib_all`, utilisÃ©e pour nos analyses.
    """)

    st.markdown("""
    ## ğŸ§¹ PrÃ©traitement des donnÃ©es
    - CrÃ©ation dâ€™une variable `delta` reprÃ©sentant la variation de vÃ©los entre deux mises Ã  jour successives
    - Nettoyage des **doublons** complets et partiels
    - Analyse des **valeurs manquantes** et **outliers**
    - CrÃ©ation de la variable `datehour`
    """)

    st.markdown("""
    ### ğŸ“‰ Valeurs aberrantes : distribution des stations par heure
    """)

    def show_date_hour_station_counts():
        datehour_df = pd.read_hdf('app/data/datehour_stations.h5')
        return px.line(datehour_df, 'datehour', 'station', labels={'datehour' : 'Date-heure', 'station' : '# de stations'}, title="Nombre de stations connues par heure (donnÃ©es d'origine)")

    st.plotly_chart(show_date_hour_station_counts())

    st.markdown("""
    ### ğŸ“¦ Distribution des valeurs (stations par heure)
    """)

    def show_date_hour_station_boxplot():
        datehour_df = pd.read_hdf('app/data/datehour_stations.h5')
        return px.box(datehour_df, 'station', labels={'station' : 'Nb de station par heure'}, title='Distribution de nombre de stations par heure')

    st.plotly_chart(show_date_hour_station_boxplot())

    st.markdown("""
    ## ğŸ“ Clusterisation spatiale des stations
    Les stations ont Ã©tÃ© regroupÃ©es selon leur proximitÃ© gÃ©ographique Ã  lâ€™aide de **KMeans**.

    Cela permet :
    - de lisser les variations locales,
    - de corriger lâ€™asymÃ©trie du dataset,
    - et dâ€™analyser les zones plutÃ´t que chaque station individuellement.

    Nombre optimal de clusters : 53 Ã  183 selon la granularitÃ©.
    """)

    def show_clusters_map():
        stations = pd.read_hdf('app/data/clusters.h5')
        borders = []
        for l in sorted(stations.labels.unique()):
            borders.append(get_border(stations[stations.labels==l], l))
        geo = points_to_geo_json(borders)
        return draw_stations_choroplethmap_scatter(geo, stations, ret=True)

    st.plotly_chart(show_clusters_map())

    st.markdown("""
    ## ğŸ“Š Tendances dâ€™utilisation du service
    Quelques tendances notables observÃ©es :
    - Pic dâ€™utilisation entre 5h-8h et 15h-20h
    - ActivitÃ© rÃ©duite en week-end et pendant les fÃªtes
    - Stations vides plus frÃ©quentes en matinÃ©e
    """)

    st.markdown("""
    ## â˜ï¸ Analyse de la corrÃ©lation avec la mÃ©tÃ©o
    Nous avons croisÃ© les donnÃ©es VÃ©libâ€™ avec les donnÃ©es MÃ©tÃ©o France :
    - TempÃ©rature moyenne horaire (Â°C)
    - PrÃ©cipitations horaires (mm)

    RÃ©sultats :
    - **TempÃ©rature** : -0.0006
    - **PrÃ©cipitations** : -0.0024

    Aucune corrÃ©lation significative nâ€™a Ã©tÃ© observÃ©e sur la pÃ©riode hivernale.
    """)

    st.markdown("""
    > ğŸ” **Limite :** une Ã©tude sur lâ€™ensemble de lâ€™annÃ©e permettrait dâ€™affiner ces observations et de rÃ©vÃ©ler des effets saisonniers plus marquÃ©s.
    """)
